<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        siyuan&#39;s blog | SJTU
    </title>
    <!-- 图标 -->
    <link rel="icon" href="/img/favicon.png">
    <!-- 字体 -->
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&family=JetBrains+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <!-- 样式 -->
    <link rel="stylesheet" href="/css/style.css">
<meta name="generator" content="Hexo 8.1.1"></head>

<body>
    <!-- 顶部进度条：颜色已改为 FFC800 (黄色) -->
    <div id="progress-bar"
        style="position: fixed; top: 0; left: 0; height: 3px; background: #FFC800; width: 0%; z-index: 9999; transition: width 0.1s;">
    </div>

    <nav class="navbar">
        <div class="nav-left">
            <div class="menu">
                <a href="/">Home</a>
                <a href="/archives">Archives</a>
                <a href="/about">About Me</a>
            </div>
        </div>
        <div class="nav-right">
            <a href="mailto:siyuanzhang@sjtu.edu.cn" class="nav-icon" title="Email Me">
                <svg viewBox="0 0 24 24">
                    <path
                        d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z" />
                </svg>
            </a>
            <a href="https://github.com/ssyzhang" target="_blank" class="nav-icon" title="Visit my GitHub">
                <svg viewBox="0 0 24 24">
                    <path
                        d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" />
                </svg>
            </a>
        </div>
    </nav>

    <main>
        <div class="vscode-wrapper">
    <!-- 标题栏 -->
    <div class="window-header">
        <div class="traffic-lights">
            <div class="dot close"></div>
            <div class="dot minimize"></div>
            <div class="dot maximize"></div>
        </div>
        <!-- 标题栏文字居中 -->
        <div style="margin: 0 auto; color: #999; font-size: 0.8rem; font-family: sans-serif;">
            day6:Ollama本地部署LLM - Hello World!
        </div>
    </div>

    <div class="vscode-body">
        <!-- 侧边栏 -->
        <div class="vscode-sidebar">
            <div class="side-icon active"></div>
            <div class="side-icon"></div>
            <div class="side-icon"></div>
        </div>

        <!-- 内容区 -->
        <div style="flex: 1; background: var(--vscode-bg);">
            <!-- 标签页 -->
            <div style="background: #1e1e1e; height: 35px; display: flex; border-bottom: 1px solid #252526;">
                <div
                    style="padding: 0 20px; display: flex; align-items: center; color: #fff; border-top: 1px solid var(--accent-color); background: #1e1e1e; font-size: 0.8rem; border-right: 1px solid #252526;">
                    <span style="color: #f1e05a; margin-right: 8px; font-weight: bold;">JS</span>
                    day6:Ollama本地部署LLM.md
                </div>
            </div>

            <!-- 面包屑 -->
            <div style="padding: 10px 40px; color: #555; font-size: 0.8rem; font-family: monospace;">
                src > posts > day6:ollama本地部署llm
            </div>

            <!-- 正文 -->
            <article class="post-content">
                <h1>
                    day6:Ollama本地部署LLM
                </h1>
                <div style="color: #666; margin-bottom: 30px; font-family: monospace; font-size: 0.8rem;">
                    // Author: SiyuanZhang<br>
                    // Published: 2025-12-09
                </div>

                <h2 id="Ollama本地部署LLM"><a href="#Ollama本地部署LLM" class="headerlink" title="Ollama本地部署LLM"></a><center>Ollama本地部署LLM</center></h2><hr>
<ol>
<li>下载Ollama即可实现开源大模型在本地的部署,实现了数据的安全</li>
</ol>
<ul>
<li>相关指令如下</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama list</span><br><span class="line">ollama run qwen2.5:3b</span><br><span class="line">ollama --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>使用langchain调用本地Ollama模型</li>
</ol>
<ul>
<li>使用<code>ChatOllama</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> ChatOllama</span><br><span class="line">llm_1 = ChatOllama(model=<span class="string">&quot;qwen2.5:3b&quot;</span>, base_url=<span class="string">&quot;http://localhost:11434&quot;</span>)</span><br><span class="line">llm_1.invoke(<span class="string">&quot;你是谁&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>C:\Users\siyuanzhang\AppData\Local\Temp\ipykernel_2856\53624327.py:2: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.
  llm_1 = ChatOllama(model=&quot;qwen2.5:3b&quot;, base_url=&quot;http://localhost:11434&quot;)





AIMessage(content=&#39;我是Qwen，是阿里巴巴推出的一种超大规模语言模型。我会回答与我的设定和训练内容相关的问题，请你放心提问关于你想要领域的问题，欢迎向我询问！&#39;, additional_kwargs={}, response_metadata={&#39;model&#39;: &#39;qwen2.5:3b&#39;, &#39;created_at&#39;: &#39;2025-12-10T08:01:11.4095119Z&#39;, &#39;message&#39;: {&#39;role&#39;: &#39;assistant&#39;, &#39;content&#39;: &#39;&#39;}, &#39;done&#39;: True, &#39;done_reason&#39;: &#39;stop&#39;, &#39;total_duration&#39;: 3751482400, &#39;load_duration&#39;: 3277307000, &#39;prompt_eval_count&#39;: 31, &#39;prompt_eval_duration&#39;: 34987200, &#39;eval_count&#39;: 39, &#39;eval_duration&#39;: 367443100}, id=&#39;lc_run--019b0747-3c3b-7f62-b72c-2e453f26b00f-0&#39;)
</code></pre>
<ul>
<li>使用<code>ChatOpenAi</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line">llm_2 = ChatOpenAI(model=<span class="string">&quot;qwen2.5:3b&quot;</span>, base_url=<span class="string">&quot;http://localhost:11434/v1&quot;</span>,openai_api_key=<span class="string">&quot;666&quot;</span>)</span><br><span class="line">llm_2.invoke(<span class="string">&quot;你是谁&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>AIMessage(content=&#39;我是Qwen，阿里云开发的超大规模语言模型。我在阿里巴巴集团的支持下训练，能够生成各种各样的文本，比如故事、剧本、编程代码等，请您放心地向我提问或交流。如有任何问题，请尽管告诉我！我在这里帮助你。&#39;, additional_kwargs={&#39;refusal&#39;: None}, response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 58, &#39;prompt_tokens&#39;: 31, &#39;total_tokens&#39;: 89, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: None}, &#39;model_provider&#39;: &#39;openai&#39;, &#39;model_name&#39;: &#39;qwen2.5:3b&#39;, &#39;system_fingerprint&#39;: &#39;fp_ollama&#39;, &#39;id&#39;: &#39;chatcmpl-218&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None}, id=&#39;lc_run--019b0386-753f-7fc2-98b4-2d25cb265585-0&#39;, usage_metadata={&#39;input_tokens&#39;: 31, &#39;output_tokens&#39;: 58, &#39;total_tokens&#39;: 89, &#39;input_token_details&#39;: {}, &#39;output_token_details&#39;: {}})
</code></pre>
<ol start="3">
<li>使用langchain调用Ollama embedding模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line">embeddings = OllamaEmbeddings(model=<span class="string">&quot;nomic-embed-text:latest&quot;</span>, base_url=<span class="string">&quot;http://localhost:11434&quot;</span>)</span><br><span class="line">vector = embeddings.embed_query(<span class="string">&quot;你好!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(vector))</span><br></pre></td></tr></table></figure>

<pre><code>768
</code></pre>
<ol start="4">
<li>one-API搭建大模型网关</li>
</ol>
<blockquote>
<p>这是一个非常繁琐和复杂的过程,需要时间,但在配置中能学到很多知识</p>
</blockquote>
<ul>
<li>首先下载<code>wsl</code>,用于承载接下来安装的Docker</li>
<li>下载Docker Desktop,用于对镜像的控制</li>
<li>完成以上步骤后,在命令行中输入命令下载并运行one-api的docker</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name one-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v E:\MYDATA\one-api:/data justsong/one-api</span><br></pre></td></tr></table></figure>
<ul>
<li>打开<code>http://localhost:3000</code>,该网址即为one-api的个人控制台,你需要在里面配置不同的模型运行商或者本地Ollama的模型,具体过程为选择方式,选择模型,输入你在各大网站的api_key,保存后即可完成配置</li>
<li>创建令牌,即可得到一个统一的api_key,之后在langchain中不用频繁输入各大厂商的api_key,只需统一输入这个令牌api_key,即可访问所有你上一步配置中保存好的模型(one-API兼容chatopenai)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#不论本地的还是购买的api key都可以使用one api统一调用,接口统一,非常方便</span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_openai.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> load_key</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = load_key(<span class="string">&quot;ONE_API_KEY&quot;</span>)</span><br><span class="line">llm_oneapi_ollama = ChatOpenAI(model=<span class="string">&quot;qwen2.5:3b&quot;</span>, base_url=<span class="string">&quot;http://localhost:3000/v1&quot;</span>)</span><br><span class="line">llm_oneapi_aliyun = ChatOpenAI(model=<span class="string">&quot;qwen-plus&quot;</span>, base_url=<span class="string">&quot;http://localhost:3000/v1&quot;</span>)</span><br><span class="line">embedding_oneapi_ollama=OpenAIEmbeddings(model=<span class="string">&quot;nomic-embed-text:latest&quot;</span>, base_url=<span class="string">&quot;http://localhost:3000/v1&quot;</span>,check_embedding_ctx_length=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(llm_oneapi_ollama.invoke(<span class="string">&quot;你是什么版本?&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(llm_oneapi_aliyun.invoke(<span class="string">&quot;你是什么版本?&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(embedding_oneapi_ollama.embed_query(<span class="string">&quot;你好!&quot;</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>content=&#39;我是一个最新的AI助手模型，持续在迭代和学习中。每次与您的交流都帮助我变得更强大、更了解世界。您有任何问题或需求，我都随时准备帮助您。如何开始我们的对话呢？&#39; additional_kwargs={&#39;refusal&#39;: None} response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 47, &#39;prompt_tokens&#39;: 33, &#39;total_tokens&#39;: 80, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: None}, &#39;model_provider&#39;: &#39;openai&#39;, &#39;model_name&#39;: &#39;qwen2.5:3b&#39;, &#39;system_fingerprint&#39;: None, &#39;id&#39;: &#39;chatcmpl-98b795bd93fa42dab4cbba6e09f0ae15&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None} id=&#39;lc_run--019b075c-13a2-7e33-bebd-28993e6abd62-0&#39; usage_metadata={&#39;input_tokens&#39;: 33, &#39;output_tokens&#39;: 47, &#39;total_tokens&#39;: 80, &#39;input_token_details&#39;: {}, &#39;output_token_details&#39;: {}}
content=&#39;我是通义千问系列的最新版本，但具体版本号可能需要查看官方文档或发布说明来确定。如果您有特定的问题或需要帮助，我可以尽力提供支持！&#39; additional_kwargs={&#39;refusal&#39;: None} response_metadata={&#39;token_usage&#39;: {&#39;completion_tokens&#39;: 38, &#39;prompt_tokens&#39;: 12, &#39;total_tokens&#39;: 50, &#39;completion_tokens_details&#39;: None, &#39;prompt_tokens_details&#39;: {&#39;audio_tokens&#39;: None, &#39;cached_tokens&#39;: 0}}, &#39;model_provider&#39;: &#39;openai&#39;, &#39;model_name&#39;: &#39;qwen-plus&#39;, &#39;system_fingerprint&#39;: None, &#39;id&#39;: &#39;chatcmpl-8dfbb2f4-22c7-4c81-b00c-690e168424fb&#39;, &#39;finish_reason&#39;: &#39;stop&#39;, &#39;logprobs&#39;: None} id=&#39;lc_run--019b075c-1669-7af0-8580-20b7a2f2d3c3-0&#39; usage_metadata={&#39;input_tokens&#39;: 12, &#39;output_tokens&#39;: 38, &#39;total_tokens&#39;: 50, &#39;input_token_details&#39;: {&#39;cache_read&#39;: 0}, &#39;output_token_details&#39;: {}}
768
</code></pre>
<ol start="5">
<li>FastGPT构建本地知识问答库</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

            </article>
        </div>
    </div>
</div>
    </main>

    <footer
        style="text-align: center; padding: 50px; color: #444; font-size: 0.8rem; font-family: 'JetBrains Mono', monospace;">
        <p>SiyuanZhang @ SJTU | SYSTEM ONLINE</p>
    </footer>

    <!-- 脚本部分 -->
    <script>
        window.onscroll = function () {
            var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
            var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
            var scrolled = (winScroll / height) * 100;
            document.getElementById("progress-bar").style.width = scrolled + "%";
        };
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.net.min.js"></script>

    <script>
        if (window.innerWidth > 768) {
            VANTA.NET({
                el: "body",
                mouseControls: true,
                touchControls: true,
                gyroControls: false,
                minHeight: 200.00,
                minWidth: 200.00,
                scale: 1.00,
                scaleMobile: 1.00,
                color: 0xFFC800,       // 已改为黄色
                backgroundColor: 0x050505,
                points: 8.00,
                maxDistance: 22.00,
                spacing: 40.00
            })
        }
    </script>
</body>

</html>